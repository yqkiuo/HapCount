# Snakefile for Phasing Pipeline

# Define rule order for logical workflow
ruleorder:
    haplotag > count_ps_reads > shapeit_phasing > whatshap_phasing


# define references files
def get_reference_files(wildcards):
    ## Return appropriate reference files based on genome build and chromosome
    build = config["genome_build"]
    chrom = wildcards.chrom if hasattr(wildcards, 'chrom') else None
    
    refs = {
        "genome_fa": config["references"][build]["genome_fa"] ## ref for whatshap
    }
    
    if chrom:
        refs.update({
            "shapeit_map": config["references"][build]["shapeit"]["map"].format(chrom=chrom),
            "shapeit_ref": config["references"][build]["shapeit"]["ref"].format(chrom=chrom)
        })
    
    return refs


# Rule to run WhatsHap phasing
rule whatshap_phasing:
    input:
        vcf = "results/{sample}.vcf.gz",
        bam = "input/{sample}.bam"ï¼Œ
        ref = lambda wildcards: get_reference_files(wildcards)["genome_fa"]
    output:
        filtered_vcf = "results/whatshap/{sample}.filtered.vcf.gz"
        phased_vcf = "results/whatshap/{sample}.phased.vcf.gz"
    threads: config["resources"]["whatshap_threads"]
    params:
        whatshap_params = config["parameters"]["whatshap"]["phase_params"]
	min_dp = config.get("min_dp", 15)
    log:
        "logs/whatshap/{sample}.log"
    conda:
        "envs/whatshap.yaml"
    shell:
        """
        bcftools view -m2 -M2 -f PASS \
	    -i 'GT="het" & FORMAT/DP > {params.min_dp}' \
       	    -Oz -o {output.filtered_vcf} {input.vcf}"
        tabix -f -p vcf {output.filtered_vcf}

        whatshap phase {params.whatshap_params} \
	    -o {output.phased_vcf} \
	    {input.vcf} {input.bam} 2> {log}
	   
        tabix -f -p vcf {output.phased_vcf}
	    rm {output.filtered_vcf}
        """

rule manual_phasing:
    input:
        vcf = "results/whatshap/{sample}.phased.vcf.gz"
    output:
        vcf = "results/whatshap/{sample}.phased.manual.vcf.gz"
    params:
        chrom = lambda wildcards: wildcards.chrom
    shell:
        """
	## Process both "chr1" and "1" formats consistently
    ## Keep it or not?
        zcat {input.vcf} | \
        sed 's/##contig=<ID=chr\([0-9XYM]\+\),/##contig=<ID=\1,/' | \
        sed 's/^chr//' | \
        awk -v OFS="\\t" 'BEGIN {{FS=OFS}}
            /^#/ {{print}}
            !/^#/ {{
                if (index($9, "PS") == 0) {{
                    $9=$9":PS";
                    $10=$10":"$2;
                    gsub(/\\//, "|", $10);
                    print;
                }} else {{ print }}
            }}' | bgzip -c > {output.vcf}
        tabix -f -p vcf {output.vcf}

        """

# Rule to run SHAPEIT phasing
rule shapeit_phasing:
    input:
        vcf = rules.manual_phasing.output.vcf,
	    map_file = lambda wildcards: get_reference_files(wildcards)["shapeit_map"],
	    ref_fie = lambda wildcards: get_reference_files(wildcards)["shapeit_ref"]
    output:
        shaped_vcf = "results/shapeit/{sample}/chr{chrom}.phased.vcf.gz",
        bingraph = "results/shapeit/{sample}/chr{chrom}.bingraph"
    threads: config["resources"]["shapeit_threads"]
    params:
        shapeit_params = config["parameters"]["shapeit"]["base_params"]
        chrom = lambda wildcards: wildcards.chrom
    log:
        "logs/shapeit/{sample}_chr{chrom}.log"
    conda:
        "envs/shapeit.yaml"
    shell:
	"""
    ## run SHAPEIT4 without chr prefix
    ## run it or not?
    zcat {input.vcf} | \
    sed 's/##contig=<ID=chr\([0-9XYM]\+\),/##contig=<ID=\1,/' | \
    sed 's/^chr//' | \
	shapeit4 {params.shapeit_params} \
        --input - \
        --map {input.map_file} \
        --reference {input.ref_file} \
        --region {params.chrom} \
	    --output {output.shaped_vcf}.tmp \
	    --bingraph {output.bingraph} 2> {log}

	## adding chr if necessary
	if [ "{config[use_chr_prefix]}" = "true" ]; then
    ## Preprocess VCF headers and add chr prefix
	    zcat {output.shaped_vcf}.tmp | \
	    awk -v OFS=\"\t\" '/^#/{print} !/^#/{\$1=\"chr\"\$1; print}' | \
	    sed -i 's/##contig=<ID=\([0-9XYM]\+\)>/##contig=<ID=chr\1>/' | \
	    bgzip -c > {output.shaped_vcf}.
        
    else    	    
	    mv {output.shaped_vcf}.tmp {output.shaped_vcf}
	fi
    
    tabix -f -p vcf {output.shaped_vcf} 
    rm {output.shaped_vcf}.tmp

	## change phasing in whatshap by shapeit
    python3 scripts/find_PS_to_update.py \
    {output.shaped_vcf} {input.vcf} \
    results/whatshap/{wildcards.sample}_chr{wildcards.chrom}.updated.vcf.gz

    tabix -f -p vcf results/whatshap/{wildcards.sample}_chr{wildcards.chrom}.updated.vcf.gz

	"""

# Rule to run haplotag per chromosome
rule haplotag:
    input:
        vcf = "results/whatshap/{sample}_chr{chrom}.updated.vcf.gz",
        bam = "input/{sample}.bam",
        ref = lambda wildcards: config["references"][config["genome_build"]]["genome_fa"]
    output:
        tagged_bam = "results/haplotag/{sample}_chr{chrom}.haplotagged.bam",
        bai = "results/haplotag/{sample}_chr{chrom}.haplotagged.bam.bai"
    params:
        haplotag_params = config.get("haplotag_params", ""),
        region = lambda wildcards: f"chr{wildcards.chrom}" if config["use_chr_prefix"] else wildcards.chrom
    log:
        "logs/haplotag/{sample}_chr{chrom}.log"
    conda:
        "envs/haplotag.yaml"
    shell:
        """
        # Run haplotag for the specific chromosome
        whatshap haplotag \
            --reference {input.ref} \
            --region {params.region} \
            --output {output.tagged_bam} \
            {input.vcf} {input.bam} 2> {log}
        
        # Index the output BAM
        samtools index {output.tagged_bam}
        """

#### counting rules ####

def get_counting_script(wildcards):
    ## Return the appropriate counting script path based on datatype
    script_map = {
        "scRNA": "count_haplotag_scRNA.sh",
        "bulkRNA": "count_haplotag_bulk.sh",
        "bulkDNA": "count_haplotag_bulk.sh",  # WGS and WES
        "bulkmethylation": "count_haplotag_meth.sh"
    }
    return f"scripts/{script_map[wildcards.datatype]}"

# Common rule template
def counting_rule(datatype):
    """Generate counting rule for a specific datatype"""
    return f"""
rule count_{datatype}:
    input:
        bam = rules.haplotag.output.tagged_bam,
    output:
        counts = "results/counts/{{sample}}_{datatype}.{chrom}.counts.tsv"
    params:
        script = get_counting_script("{datatype}"),
        binsize = config["binsize"] 
        chrom = lambda wildcards: wildcards.chrom
    log:
        "logs/counts/{{sample}}_{datatype}.log"
    conda:
        "envs/counting.yaml"
    shell:
        "bash {{params.script}} {{input.bam}} {f'{{params.binsize}}' if datatype in ['scRNA', 'bulkRNA'] else ''} {{output.counts}} 2> {{log}}"
    """

# Generate rules for all datatypes
for datatype in config["datatypes"]:
    counting_rule(datatype)



#### aggregating rules ####

def get_aggre_script(wildcards):
    ## Return the appropriate counting script path based on datatype
    script_map = {
        "scRNA": "aggre_haplotag_scRNA.sh",
        "bulkRNA": "aggre_haplotag_bulk.sh",
        "bulkDNA": "aggre_haplotag_bulk.sh",  
        "bulkmethylation": "aggre_haplotag_meth.sh"
    }
    return f"scripts/{script_map[wildcards.datatype]}"


def aggregating_rule(datatype):
    """ Generate aggregating rule for a specific datatype by binsize """
    return f"""

rule aggregate_{datatype}:
    input:
        counts = "results/counts/{{sample}}_{datatype}_chr{{chrom}}.counts.tsv"
    output:
        aggregated = "results/aggregated/tmp/{{sample}}_{datatype}_chr{{chrom}}.agg.tsv"
    params:
        script = get_aggregate_script("{datatype}"),
        binsize = config["binsizes"]
    log:
        "logs/aggregation/{{sample}}_{datatype}_chr{{chrom}}.log"
    conda:
        "envs/aggregation.yaml"
    shell:
        \"\"\"
        # Run aggregation script
        bash {{params.script}} \\
            {{input.counts}} \\
            {{params.binsize}} \\
            {{output.aggregated}} 2> {{log}}
        \"\"\"

rule aggregate_{datatype}_wholegenome:
    inputs:
        expand("results/aggregated/tmp/{{sample}}_{datatype}_chr{{chrom}}.agg.tsv",
               chrom=config["chromosomes"])
    output:
        final = "results/aggregated/{{sample}}_{datatype}.tsv"
    shell:
    \"\"\"
        # Combine all chromosome results
        cat {{input}} > {{output.final}}
        # Clean up temporary files
        rm {{input}}
    \"\"\"
    
    """

# Generate rules for all datatypes
for datatype in config["datatypes"]:
    for rule_text in generate_aggregation_rules(datatype):
        exec(rule_text)


